{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Week 3 Sample Code \n# EDA",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# load the dataset from sklearn\nimport pandas as pd\nimport numpy as np\nfrom sklearn.datasets import load_iris\niris = load_iris()\niris_nparray = iris.data\n# After data is loaded into a variable we can convert it to a numpy array or pandas dataframe\nprint(iris_nparray)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# convert into a dataframe\niris_dataframe = pd.DataFrame(iris.data, columns=iris.feature_names)\niris_dataframe['group'] = pd.Series([iris.target_names[k] for k in iris.target], dtype=\"category\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# get the mean of numeric columns\nprint(iris_dataframe.mean(numeric_only=True))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Get the median \nprint(iris_dataframe.median(numeric_only=True))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# You can get most of the statistics by using describe\niris_dataframe.describe()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# check the data for skewness\nfrom scipy.stats import skew, skewtest\nvariable = iris_dataframe['petal length (cm)']\ns = skew(variable)\nzscore, pvalue = skewtest(variable)\nprint('Skewness %0.3f z-score %0.3f p-value %0.3f'% (s, zscore, pvalue))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# check the data for kurtosis\nfrom scipy.stats import kurtosis, kurtosistest\nvariable = iris_dataframe['petal length (cm)']\nk = kurtosis(variable)\nzscore, pvalue = kurtosistest(variable)\nprint('Kurtosis %0.3f z-score %0.3f p-value %0.3f' % (k, zscore, pvalue))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Count For Categorial Data\npcts = [0, .25, .5, .75, 1]\niris_binned = pd.concat(\n    [pd.qcut(iris_dataframe.iloc[:,0], pcts, precision=1),\n    pd.qcut(iris_dataframe.iloc[:,1], pcts, precision=1),\n    pd.qcut(iris_dataframe.iloc[:,2], pcts, precision=1),\n    pd.qcut(iris_dataframe.iloc[:,3], pcts, precision=1)],\n    join='outer', axis = 1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "print(iris_binned)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "print(iris_binned.describe())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# understanding frequencies\nprint(iris_dataframe['group'].value_counts())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# understanding frequencies\nprint(pd.crosstab(iris_dataframe['group'], iris_binned['petal length (cm)']))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# EDA Visualization\n# Make histogram for the given data set\niris_dataframe.hist()\npyplot.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.75, wspace=0.50)\n\n\n# Make the density plots\niris_dataframe.plot(kind='density', subplots=True, layout=(4,4), sharex=False)\n\n\n# Make the box plots\niris_dataframe.plot(kind='box', subplots=True, layout=(4,4), sharex=False,sharey=False)\npyplot.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.75, wspace=0.50)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "%pip install seaborn",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Getting the covariance matrix\nimport seaborn as sn\nfrom matplotlib import pyplot\ncorrelations = iris_dataframe.corr()\n# Print the matrix itself\nprint(correlations)\n## plot correlation matrix\nsn.heatmap(correlations,annot=True)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# printing the Pearson and Spearman correlation\nfrom scipy.stats import spearmanr\nfrom scipy.stats import pearsonr\n\na = iris_dataframe['sepal length (cm)']\nb = iris_dataframe['sepal width (cm)']\nrho_coef, rho_p = spearmanr(a, b)\nr_coef, r_p = pearsonr(a, b)\nprint('Pearson r %0.3f | Spearman rho %0.3f'% (r_coef, rho_coef))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# running the chi-square test\nfrom scipy.stats import chi2_contingency\n\ntable = pd.crosstab(iris_dataframe['group'], iris_binned['petal length (cm)'])\nchi2, p, dof, expected = chi2_contingency(table.values)\nprint('Chi-square %0.2f p-value %0.3f' % (chi2, p))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# transformation of data distribution\n\nfrom scipy.stats import pearsonr\n\ntransformations = {'x': lambda x: x,\n                  '1/x': lambda x: 1/x,\n                  'x**2': lambda x: x**2,\n                  'x**3': lambda x: x**3,\n                  'log(x)': lambda x: np.log(x)}\n\na = iris_dataframe['sepal length (cm)']\nb = iris_dataframe['sepal width (cm)']\n\nfor name, func in transformations.items():\n    # Using .apply() to transform the series 'b'\n    b_transformed = b.apply(func)\n    \n    pearsonr_coef, pearsonr_p = pearsonr(a, b_transformed)\n    print('Transformation: %s \\t Pearson\\'s r: %0.3f' % (name, pearsonr_coef))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}