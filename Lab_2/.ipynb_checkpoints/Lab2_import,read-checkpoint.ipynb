{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6899bf6",
   "metadata": {},
   "source": [
    "#  Lab: Lab  2\n",
    "\n",
    "## ðŸ‘¤ Student Information\n",
    "\n",
    "| Field           | Entry (fill in)                |\n",
    "|-----------------|--------------------------------|\n",
    "| **Name**        | _Type your full name here_     |\n",
    "| **Student #**   | _Type your student number_     |\n",
    "| **Course/Section** |AIG150 NAA    |\n",
    "| **Date**        | _YYYY-MM-DD_                   |\n",
    "\n",
    "\n",
    "# Submission Colab Notebook\n",
    "\n",
    "Submit your completed Colab notebook file:\n",
    " Lab2questions_DataAccess_Cleaning_yourname_answers.ipynb\n",
    "Make sure:\n",
    "All code cells run without errors.\n",
    "Each question has your answer included in a text cell below the code.\n",
    "The notebook is self-contained (no external screenshots needed â€” outputs remain in the notebook).\n",
    "\n",
    "---# LAB 2 Data Access & Cleaning Lab â€” 20 Q&A Exercises\n",
    "\n",
    "# Upload the following files\n",
    "This notebook uses the sample files created alongside it:\n",
    "\n",
    "- `students.csv`\n",
    "- `enrollments.csv`\n",
    "- `measurements_large.csv`\n",
    "- `transactions.tsv` (tab-delimited)\n",
    "- `products.json`\n",
    "- `app.log`\n",
    "- `school.db` (SQLite)\n",
    "- `inventory.html`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59233960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "255ee9c1",
   "metadata": {},
   "source": [
    "## Q1. Read `students.csv` and print the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2560eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   student_id   name  age program   gpa\n",
      "0           1  Alice   22      AI  3.90\n",
      "1           2    Bob   27      DS  2.46\n",
      "2           3  Cathy   24      DS  3.10\n",
      "3           4    Dan   21      DS  3.82\n",
      "4           5    Eva   21      DS  2.27\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"students.csv\")\n",
    "# Print the first 5 rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfe7848",
   "metadata": {},
   "source": [
    "## Q2. Print only the `name` and `gpa` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ac851ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name   gpa\n",
      "0   Alice  3.90\n",
      "1     Bob  2.46\n",
      "2   Cathy  3.10\n",
      "3     Dan  3.82\n",
      "4     Eva  2.27\n",
      "5   Frank  3.05\n",
      "6   Grace  3.50\n",
      "7    Hank  3.34\n",
      "8     Ivy  2.94\n",
      "9    Jack  2.41\n",
      "10   Kara  2.98\n",
      "11   Liam  2.74\n",
      "12    Mia  2.95\n",
      "13   Nina  2.73\n",
      "14   Omar  3.68\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"students.csv\")\n",
    "\n",
    "# Select and print specific columns\n",
    "print(df[[\"name\", \"gpa\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c8bd38",
   "metadata": {},
   "source": [
    "## Q3. Read `transactions.tsv` (tab-delimited) and show rows 3â€“7 (0-based index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2335a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  txn_id   user  amount   status\n",
      "3  T1003    dan  136.43  pending\n",
      "4  T1004  alice  110.89   failed\n",
      "5  T1005  alice  153.52  pending\n",
      "6  T1006  alice   73.34   failed\n",
      "7  T1007    bob   57.88       ok\n"
     ]
    }
   ],
   "source": [
    "# Read TSV file (tab-separated)\n",
    "df = pd.read_csv(\"transactions.tsv\", sep=\"\\t\")\n",
    "# Show rows with index 3 to 7\n",
    "print(df.iloc[3:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473435fa",
   "metadata": {},
   "source": [
    "## Q4. Using `.loc`, show `txn_id` and `amount` for all rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d32c18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   txn_id  amount\n",
      "0   T1000   52.23\n",
      "1   T1001   63.50\n",
      "2   T1002  188.27\n",
      "3   T1003  136.43\n",
      "4   T1004  110.89\n",
      "5   T1005  153.52\n",
      "6   T1006   73.34\n",
      "7   T1007   57.88\n",
      "8   T1008   61.14\n",
      "9   T1009  161.74\n",
      "10  T1010  178.22\n",
      "11  T1011  196.89\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[:, [\"txn_id\", \"amount\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a45074f",
   "metadata": {},
   "source": [
    "## Q5. Stream `measurements_large.csv` in chunks of 1000 and compute global min/max of each chunk `reading`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef0b06cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Minimum Values:\n",
      "sensor_id    101.00\n",
      "reading       14.66\n",
      "dtype: float64\n",
      "\n",
      "Global Maximum Values:\n",
      "sensor_id    104.00\n",
      "reading       85.58\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 1000\n",
    "\n",
    "global_min = None\n",
    "global_max = None\n",
    "\n",
    "for chunk in pd.read_csv(\"measurements_large.csv\", chunksize=chunk_size):\n",
    "    # Compute min and max for this chunk (column-wise)\n",
    "    chunk_min = chunk.min(numeric_only=True)\n",
    "    chunk_max = chunk.max(numeric_only=True)\n",
    "    \n",
    "    # Update global min\n",
    "    if global_min is None:\n",
    "        global_min = chunk_min\n",
    "        global_max = chunk_max\n",
    "    else:\n",
    "        global_min = pd.concat([global_min, chunk_min], axis=1).min(axis=1)\n",
    "        global_max = pd.concat([global_max, chunk_max], axis=1).max(axis=1)\n",
    "\n",
    "print(\"Global Minimum Values:\")\n",
    "print(global_min)\n",
    "\n",
    "print(\"\\nGlobal Maximum Values:\")\n",
    "print(global_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf08b7d",
   "metadata": {},
   "source": [
    "## Q6. Still streaming, compute min/max of reading by grouping `sensor_id` and print the grouping for each chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9772859f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chunk 1\n",
      "             min    max\n",
      "sensor_id              \n",
      "101        18.74  84.16\n",
      "102        17.94  79.24\n",
      "103        24.39  78.04\n",
      "104        20.92  76.37\n",
      "\n",
      "Chunk 2\n",
      "             min    max\n",
      "sensor_id              \n",
      "101        19.50  76.91\n",
      "102        14.66  77.20\n",
      "103        15.84  85.58\n",
      "104        24.23  76.56\n",
      "\n",
      "Chunk 3\n",
      "             min    max\n",
      "sensor_id              \n",
      "101        23.02  77.09\n",
      "102        23.46  74.24\n",
      "103        24.99  79.52\n",
      "104        18.85  79.91\n",
      "\n",
      "Chunk 4\n",
      "             min    max\n",
      "sensor_id              \n",
      "101        17.66  80.90\n",
      "102        19.07  77.99\n",
      "103        17.63  77.35\n",
      "104        19.64  74.09\n",
      "\n",
      "Chunk 5\n",
      "             min    max\n",
      "sensor_id              \n",
      "101        23.70  76.11\n",
      "102        25.64  83.90\n",
      "103        21.89  83.75\n",
      "104        23.04  75.15\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 1000\n",
    "\n",
    "for i, chunk in enumerate(pd.read_csv(\"measurements_large.csv\", chunksize=chunk_size)):\n",
    "    # Group within this chunk\n",
    "    grouped = chunk.groupby(\"sensor_id\")[\"reading\"].agg([\"min\", \"max\"])\n",
    "    \n",
    "    print(f\"\\nChunk {i + 1}\")\n",
    "    print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2038c3e6",
   "metadata": {},
   "source": [
    "## Q7. Load `products.json` into a DataFrame and show items in the `Gadgets` category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "10f75494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id       name category  price  in_stock\n",
      "4    5   Widget-5  Gadgets  76.08      True\n",
      "8    9   Widget-9  Gadgets  62.94      True\n",
      "11  12  Widget-12  Gadgets  28.95      True\n",
      "13  14  Widget-14  Gadgets  52.84      True\n",
      "14  15  Widget-15  Gadgets  48.57     False\n"
     ]
    }
   ],
   "source": [
    "# Load JSON file\n",
    "df = pd.read_json(\"products.json\")\n",
    "\n",
    "# Show only items in the Gadgets category\n",
    "gadgets = df[df[\"category\"] == \"Gadgets\"]\n",
    "\n",
    "print(gadgets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5699953d",
   "metadata": {},
   "source": [
    "## Q8. Read `app.log` as text and show the first 5 `ERROR` lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0174b87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-01T09:10:00 [ERROR] User login\n",
      "2025-09-01T13:05:00 [ERROR] Timeout retry\n",
      "2025-09-01T13:30:00 [ERROR] Timeout retry\n",
      "2025-09-01T16:25:00 [ERROR] DB slow query\n",
      "2025-09-01T16:35:00 [ERROR] Cache miss\n"
     ]
    }
   ],
   "source": [
    "error_lines = []\n",
    "\n",
    "with open(\"app.log\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        if \"ERROR\" in line:\n",
    "            error_lines.append(line.strip())\n",
    "        if len(error_lines) == 5:\n",
    "            break\n",
    "\n",
    "# Print the first 5 ERROR lines\n",
    "for line in error_lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864a9c54",
   "metadata": {},
   "source": [
    "**Explanation:** Plain-text logs can be processed line-by-line without loading into a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e89c01a",
   "metadata": {},
   "source": [
    "## Q9. Connect to `school.db` and select students with `gpa >= 3.5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b01e3662-55ba-479a-9678-05c4d7514b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Alice', 22, 'AI', 3.9)\n",
      "(4, 'Dan', 21, 'DS', 3.82)\n",
      "(7, 'Grace', 25, 'AI', 3.5)\n",
      "(15, 'Omar', 25, 'CS', 3.68)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(\"school.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Query students with GPA >= 3.5\n",
    "cursor.execute(\"SELECT * FROM students WHERE gpa >= 3.5\")\n",
    "\n",
    "# Fetch and display results\n",
    "rows = cursor.fetchall()\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "# Close connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ee5d21",
   "metadata": {},
   "source": [
    "## Q10. Read the HTML table from `inventory.html`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b06aca50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id      name  category  price  in_stock\n",
      "0   1  Widget-1  Supplies  11.74     False\n",
      "1   2  Widget-2  Supplies  55.30     False\n",
      "2   3  Widget-3     Tools  75.89     False\n",
      "3   4  Widget-4     Tools  75.18      True\n",
      "4   5  Widget-5   Gadgets  76.08      True\n"
     ]
    }
   ],
   "source": [
    "tables = pd.read_html(\"inventory.html\")\n",
    "\n",
    "# Show the first table (most pages only have one main table)\n",
    "df = tables[0]\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7113e6b",
   "metadata": {},
   "source": [
    "**Explanation:** `pd.read_html` parses all tables; returns a list of DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a931bf",
   "metadata": {},
   "source": [
    "## Q11. Create a copy of `students` with some missing values and impute `age` with the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b0a073bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median age used for imputation: 25.0\n",
      "   student_id   name   age program   gpa\n",
      "0           1  Alice  22.0      AI  3.90\n",
      "1           2    Bob  27.0      DS  2.46\n",
      "2           3  Cathy  25.0      DS  3.10\n",
      "3           4    Dan  21.0      DS  3.82\n",
      "4           5    Eva  21.0      DS  2.27\n"
     ]
    }
   ],
   "source": [
    "students = pd.read_csv(\"students.csv\")\n",
    "students_copy = students.copy()\n",
    "\n",
    "# Introduce missing values (example)\n",
    "students_copy.loc[students_copy.sample(frac=0.1).index, \"age\"] = np.nan\n",
    "\n",
    "# Compute median\n",
    "median_age = students_copy[\"age\"].median()\n",
    "\n",
    "# Impute missing values (safe way)\n",
    "students_copy[\"age\"] = students_copy[\"age\"].fillna(median_age)\n",
    "\n",
    "print(\"Median age used for imputation:\", median_age)\n",
    "print(students_copy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b9fe2c",
   "metadata": {},
   "source": [
    "**Explanation:** `fillna(median)` is a simple numeric imputation strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89504722",
   "metadata": {},
   "source": [
    "## Q12. Convert `program` to lowercase and `name` to uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c58fad68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name program\n",
      "0  ALICE      ai\n",
      "1    BOB      ds\n",
      "2  CATHY      ds\n",
      "3    DAN      ds\n",
      "4    EVA      ds\n"
     ]
    }
   ],
   "source": [
    "students[\"program\"] = students[\"program\"].str.lower()\n",
    "students[\"name\"] = students[\"name\"].str.upper()\n",
    "\n",
    "print(students[[\"name\", \"program\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9311c2",
   "metadata": {},
   "source": [
    "**Explanation:** Use `Series.str` accessors for vectorized string ops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba55275",
   "metadata": {},
   "source": [
    "## Q13. Right-join `students` with `enrollments` on `student_id` and show the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e479318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   student_id   name   age program   gpa course_code term\n",
      "0           1  Alice  22.0      AI  3.90      AIG150  F25\n",
      "1           2    Bob  27.0      DS  2.46      BTP500  F25\n",
      "2           2    Bob  27.0      DS  2.46      AIG150  F25\n",
      "3           4    Dan  21.0      DS  3.82      BDD300  F25\n",
      "4           7  Grace  25.0      AI  3.50      SEN800  F25\n"
     ]
    }
   ],
   "source": [
    "students = pd.read_csv(\"students.csv\")\n",
    "enrollments = pd.read_csv(\"enrollments.csv\")\n",
    "\n",
    "# Right join on student_id\n",
    "result = pd.merge(students, enrollments, on=\"student_id\", how=\"right\")\n",
    "\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d39e8e",
   "metadata": {},
   "source": [
    "**Explanation:** `how='right'` keeps all rows from `enrollments` and matches from `students`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e6c396",
   "metadata": {},
   "source": [
    "## Q14. Show `enrollments` rows that had no matching `student_id` in `students` (right-only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78b211fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   student_id name  age program  gpa course_code term      _merge\n",
      "9          16  NaN  NaN     NaN  NaN      AIG150  F25  right_only\n"
     ]
    }
   ],
   "source": [
    "students = pd.read_csv(\"students.csv\")\n",
    "enrollments = pd.read_csv(\"enrollments.csv\")\n",
    "\n",
    "merged = pd.merge(\n",
    "    students,\n",
    "    enrollments,\n",
    "    on=\"student_id\",\n",
    "    how=\"right\",\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Rows that exist only in enrollments (no match in students)\n",
    "right_only = merged[merged[\"_merge\"] == \"right_only\"]\n",
    "\n",
    "print(right_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8bceb2",
   "metadata": {},
   "source": [
    "**Explanation:** use indicator=True, this will add a column named `_merge` which reveals join provenance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4a271a",
   "metadata": {},
   "source": [
    "## Q15. In the tiny grades table (wide) and `melt` to long format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b732fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = pd.DataFrame({\n",
    "    'student_id':[1,2,3],\n",
    "    'quiz1':[8,7,9],\n",
    "    'quiz2':[9,6,8]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b3a434",
   "metadata": {},
   "source": [
    "**Explanation:** `melt` stacks column headers into row values, making data 'tidy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5580c5a5-31d0-406d-beeb-831fae21770d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   student_id   quiz  score\n",
      "0           1  quiz1      8\n",
      "1           2  quiz1      7\n",
      "2           3  quiz1      9\n",
      "3           1  quiz2      9\n",
      "4           2  quiz2      6\n",
      "5           3  quiz2      8\n"
     ]
    }
   ],
   "source": [
    "grades_long = pd.melt(\n",
    "    grades,\n",
    "    id_vars=\"student_id\",      # column to keep as identifier\n",
    "    var_name=\"quiz\",           # name for former column headers\n",
    "    value_name=\"score\"         # name for values\n",
    ")\n",
    "\n",
    "print(grades_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07f0361",
   "metadata": {},
   "source": [
    "## Q16. Pivot `long` back to wide form with average score per assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a33e1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quiz        quiz1  quiz2\n",
      "student_id              \n",
      "1             8.0    9.0\n",
      "2             7.0    6.0\n",
      "3             9.0    8.0\n"
     ]
    }
   ],
   "source": [
    "grades_wide_avg = grades_long.pivot_table(\n",
    "    index=\"student_id\",      # rows\n",
    "    columns=\"quiz\",          # new columns\n",
    "    values=\"score\",          # values to fill\n",
    "    aggfunc=\"mean\"           # average in case of duplicates\n",
    ")\n",
    "\n",
    "print(grades_wide_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bf8133d1-0c8d-480e-be03-ef29122a5d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = pd.DataFrame({\n",
    "    'name':['A', 'B', 'C'],\n",
    "    'student_id':[1,2,3],\n",
    "    'quiz1':[8,7,9],\n",
    "    'quiz2':[9,6,8]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "58a1123e-b6aa-4661-a79c-93933f38a116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'name', 'category', 'price', 'in_stock']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ad3e5312-f4ce-45ae-8020-5f7ff8aca0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'student_id', 'quiz1', 'quiz2']\n"
     ]
    }
   ],
   "source": [
    "print(grades.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faf2dd7",
   "metadata": {},
   "source": [
    "## Q17. In the DataFrame df, write Python code to create two smaller DataFrames:\n",
    "\n",
    "a. containing the first 5 rows of the student_id and name columns.\n",
    "\n",
    "b. containing the next 5 rows (rows 5â€“9) of the same two columns.\n",
    "Concatenate them row-wise (`axis=0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c99384f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   student_id name\n",
      "0           1    A\n",
      "1           2    B\n",
      "2           3    C\n"
     ]
    }
   ],
   "source": [
    "# a) First 5 rows with only student_id and name\n",
    "df_part1 = grades.loc[0:4, [\"student_id\", \"name\"]]\n",
    "\n",
    "# b) Next 5 rows (rows 5â€“9) with the same columns\n",
    "df_part2 = grades.loc[5:9, [\"student_id\", \"name\"]]\n",
    "\n",
    "# Concatenate row-wise\n",
    "combined_df = pd.concat([df_part1, df_part2], axis=0)\n",
    "\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e2db5",
   "metadata": {},
   "source": [
    "**Explanation:** `pd.concat` stacks DataFrames by rows when `axis=0`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fba9e5",
   "metadata": {},
   "source": [
    "## Q18. Concatenate two DataFrames column-wise (`axis=1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "392a5ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into two DataFrames\n",
    "df_left = grades[[\"name\", \"student_id\"]]\n",
    "df_right = grades[[\"quiz1\", \"quiz2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ac46e909-bd3e-4f6a-9f18-0d56a956446d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   student_id   name  age program   gpa\n",
      "0           1  Alice   22      AI  3.90\n",
      "1           2    Bob   27      DS  2.46\n",
      "2           3  Cathy   24      DS  3.10\n",
      "3           4    Dan   21      DS  3.82\n",
      "4           5    Eva   21      DS  2.27\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"students.csv\")\n",
    "# Print the first 5 rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c52903",
   "metadata": {},
   "source": [
    "## Q19. Select students with `age >= 25` and show only `name, age, gpa`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1bf6be17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name  age   gpa\n",
      "1     Bob   27  2.46\n",
      "5   Frank   25  3.05\n",
      "6   Grace   25  3.50\n",
      "7    Hank   27  3.34\n",
      "8     Ivy   25  2.94\n",
      "9    Jack   26  2.41\n",
      "10   Kara   27  2.98\n",
      "11   Liam   28  2.74\n",
      "12    Mia   28  2.95\n",
      "13   Nina   26  2.73\n",
      "14   Omar   25  3.68\n"
     ]
    }
   ],
   "source": [
    "result = df.loc[df[\"age\"] >= 25, [\"name\", \"age\", \"gpa\"]]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61675d4e",
   "metadata": {},
   "source": [
    "## Q20. Using school.db write an SQL query joining `enrollments` with `courses` to see course titles for each enrollment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "49b4d786",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'school' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msqlite3\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m conn \u001b[38;5;241m=\u001b[39m sqlite3\u001b[38;5;241m.\u001b[39mconnect(school\u001b[38;5;241m.\u001b[39mdb)\n\u001b[0;32m      6\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124mSELECT \u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m    e.enrollment_id,\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124m    ON e.course_id = c.course_id;\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     17\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql_query(query, conn)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'school' is not defined"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect(school.db)\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    e.enrollment_id,\n",
    "    e.student_id,\n",
    "    e.course_id,\n",
    "    c.course_title\n",
    "FROM enrollments e\n",
    "JOIN courses c\n",
    "    ON e.course_id = c.course_id;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "print(df.head())\n",
    "\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
