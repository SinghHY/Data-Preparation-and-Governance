{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "VSVo7WzF0VS2",
      "metadata": {
        "id": "VSVo7WzF0VS2"
      },
      "source": [
        "#  Lab: Lab  4\n",
        "\n",
        "## ðŸ‘¤ Student Information\n",
        "\n",
        "| Field           \t| Entry (fill in)                |\n",
        "|-----------------|--------------------------------|\n",
        "| **Name**        | Harpreet Singh     |\n",
        "| **Student #**   | 011932084     |\n",
        "| **Course/Section** |AIG150 NAA    |\n",
        "| **Date**        | _YYYY-MM-DD_                   |\n",
        "\n",
        "\n",
        "**Complete All the questions**\n",
        "*  Submit the filled in answers Lab4_Answers.ipynb file and the `retail_transactions_cleaned.csv` file\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f8a3a0b",
      "metadata": {
        "id": "5f8a3a0b"
      },
      "source": [
        "\n",
        "# Handling Missing Data in Pandas\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e74815a0",
      "metadata": {
        "id": "e74815a0"
      },
      "source": [
        "# Task\n",
        "Load the \"retail_transactions_messy.csv\" file into a pandas DataFrame, identify and handle missing data, and explain the steps taken."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a3e8860",
      "metadata": {
        "id": "1a3e8860"
      },
      "source": [
        "## 1) Load the data\n",
        "\n",
        "### Subtask:\n",
        "Load the `retail_transactions_messy.csv` file into a pandas DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24d4045d",
      "metadata": {
        "id": "24d4045d"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the data from the specified CSV file into a pandas `df_retail `DataFrame as requested.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "_CfbxQ5E3zsY",
      "metadata": {
        "id": "_CfbxQ5E3zsY",
        "outputId": "8fdf7b79-f621-417c-a509-45a2b3de20db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'retail_transactions_messy.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3031827232.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_retail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'retail_transactions_messy.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf_retail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'retail_transactions_messy.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df_retail = pd.read_csv('retail_transactions_messy.csv')\n",
        "df_retail.head"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abfc318b",
      "metadata": {
        "id": "abfc318b"
      },
      "source": [
        "## 2)Inspect the data\n",
        "\n",
        "### Subtask:\n",
        "Display the head of the DataFrame and check the data types and summary statistics to get an initial understanding of the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75f5b73f",
      "metadata": {
        "id": "75f5b73f"
      },
      "source": [
        "**Reasoning**:\n",
        "Display the head of the DataFrame, check the data types, and generate descriptive statistics to understand the data structure and identify potential issues like missing values or incorrect data types.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5t_LXm1a3108",
      "metadata": {
        "id": "5t_LXm1a3108"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b94e11ae",
      "metadata": {
        "id": "b94e11ae"
      },
      "source": [
        "## 3)Identify missing data\n",
        "\n",
        "### Subtask:\n",
        "Check for missing values using `.isnull()` and `.sum()` to see which columns have missing data and how many.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5c947ba",
      "metadata": {
        "id": "d5c947ba"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate and display the number of missing values per column in the df_retail DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WvCWPvQo33Ac",
      "metadata": {
        "id": "WvCWPvQo33Ac"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3ecb4b69",
      "metadata": {
        "id": "3ecb4b69"
      },
      "source": [
        "## 4) Handle missing data\n",
        "\n",
        "### Subtask:\n",
        "Handle missing data in the `df_retail` DataFrame using appropriate methods.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab3d0e20",
      "metadata": {
        "id": "ab3d0e20"
      },
      "source": [
        "**Reasoning**:\n",
        "Handle missing data in the specified columns using appropriate methods as per the instructions.\n",
        " 1. Convert the 'order_date' column to datetime objects, coercing errors to NaT.\n",
        "\n",
        "\n",
        " 2. Fill missing values in the 'city' and 'province' columns with a placeholder like 'Unknown'.\n",
        "\n",
        "\n",
        " 3. Convert the 'quantity' column to numeric, coercing errors to NaN, and then fill missing values with the median quantity.\n",
        "\n",
        "\n",
        " 4. Convert the 'unit_price' column to numeric, coercing errors to NaN, and fill missing values with the median unit price.\n",
        "\n",
        "\n",
        " 5. Convert the 'discount' column to numeric, coercing errors to NaN, and fill missing values with 0.\n",
        "\n",
        "\n",
        " 6. Convert the 'shipping_cost' column to numeric, coercing errors to NaN, and then fill missing values with the median shipping cost.\n",
        "\n",
        "\n",
        " 7. Fill missing values in the 'comments' column with an empty string.\n",
        "\n",
        "\n",
        " 8. Drop rows where 'order_id' or 'customer_id' are missing.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dsACM16M4Jnc",
      "metadata": {
        "id": "dsACM16M4Jnc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3297f588",
      "metadata": {
        "id": "3297f588"
      },
      "source": [
        "### 5) Replace missing values for `order_date`\n",
        "\n",
        "There are several strategies for handling missing date values in the `order_date` column:\n",
        "\n",
        "*   **Replace with a specific placeholder date**: You can fill missing dates with a predefined date, such as a default or a date outside the expected range, to indicate that the original date was missing.\n",
        "*   **Forward fill (`ffill`) or Backward fill (`bfill`)**: If your data has a logical temporal order, you might use forward or backward fill to propagate the last or next valid date. However, this might not be appropriate if the missing dates are not sequential.\n",
        "*   **Drop rows with missing dates**: If the rows with missing dates are a small portion of your data and are not essential for your analysis, you could drop those rows.\n",
        "*   **Imputation based on other columns**: In some cases, you might be able to infer or estimate the missing date based on information in other columns.\n",
        "\n",
        "The choice of method depends on the nature of your data and the goals of your analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E59yrB3E4MgC",
      "metadata": {
        "id": "E59yrB3E4MgC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5abe6614",
      "metadata": {
        "id": "5abe6614"
      },
      "source": [
        "### 6) Replace missing values for `segment`\n",
        "\n",
        "For categorical columns like `segment`, you can handle missing values by:\n",
        "\n",
        "*   **Replacing with the mode**: Fill missing values with the most frequent category in the column.\n",
        "*   **Replacing with a placeholder**: Use a string like 'Unknown' or 'Missing' to indicate that the original segment was not recorded.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "scnrh_rm4Nf7",
      "metadata": {
        "id": "scnrh_rm4Nf7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ad8hxrBk00XI",
      "metadata": {
        "id": "ad8hxrBk00XI"
      },
      "source": [
        "## 7) Verify handling\n",
        "\n",
        "### Subtask:\n",
        "Check again for missing data to ensure the chosen methods were effective."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ck4tVFp4Omb",
      "metadata": {
        "id": "0ck4tVFp4Omb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "fJjMasj_3DoA",
      "metadata": {
        "id": "fJjMasj_3DoA"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "491f6eb6",
      "metadata": {
        "id": "491f6eb6"
      },
      "source": [
        "## 8) Store the cleaned data\n",
        "\n",
        "### Subtask:\n",
        "Save the `df_retail` DataFrame, which now has missing values handled, to a new CSV file named `retail_transactions_cleaned.csv`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OK-0KmcD4P1c",
      "metadata": {
        "id": "OK-0KmcD4P1c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}